{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b32258",
   "metadata": {},
   "source": [
    "# Double Deep Q-Network (DQN) with Prioritized Experience Replay using PyTorch\n",
    "Environment: LunarLander-v2\n",
    "\n",
    "### Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "555ed7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7fc63f370ca0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "is_ipython = 'inline' in plt.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "    \n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312da450",
   "metadata": {},
   "source": [
    "## Specify the Environment, and Explore the State and Action Spaces\n",
    "* Let's begin with an initializing the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05fa0d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space:  Box([-inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf], (8,), float32)\n",
      "State shape:  (8,)\n",
      "Action space:  Discrete(4)\n",
      "Number of actions:  4\n"
     ]
    }
   ],
   "source": [
    "# Create an environment\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(0);\n",
    "print('State space: ', env.observation_space)\n",
    "print('State shape: ', env.observation_space.shape)\n",
    "\n",
    "print('Action space: ', env.action_space)\n",
    "print('Number of actions: ', env.action_space.n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b9996",
   "metadata": {},
   "source": [
    "### Implement Q-Network\n",
    "Building the Network: Actor (policy) Model\n",
    "input_size = state_size\n",
    "output_size = action_size\n",
    "using same seed\n",
    "hidden_layers: fc1, fc2\n",
    "\n",
    "Define Layer of model: [FC-RELU-FC-RELU-FC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "514d85fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=64):\n",
    "        '''\n",
    "        Builds a feedforward nework with two hidden layers\n",
    "        Initialize parameters\n",
    "        \n",
    "        Params\n",
    "        =========\n",
    "        state_size (int): Dimension of each state (input_size)\n",
    "        action_size (int): dimension of each action (output_size)\n",
    "        seed (int): Random seed(using 0)\n",
    "        fc1_units (int): Size of the first hidden layer\n",
    "        fc2_units (int): Size of the second hidden layer\n",
    "        '''\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        # Add the first laer, input to hidden layer\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        # Add more hidden layer\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        \n",
    "    def forward(self, state):\n",
    "        \"\"\"\n",
    "        Forward pass through the network. Build a network that mps state -> action values.\n",
    "        \"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d9ceab",
   "metadata": {},
   "source": [
    "#Prioritized Experience Replay\n",
    "\n",
    "### Set finite memory size N\n",
    "Algorithm only stores the last N experience tuples in the replay memory, and sample uniformly at random from D when performing updates. The memory buffer does not differentiate imporant transitions and always overwrites with recent transitions owing to the finitre memory size N.\n",
    "\n",
    "Uniform sampling gives equal importance to all transitions in the replay memory\n",
    "\n",
    "We store each experienced tuple in the buffer as we are interacting with the environment and then sample a small bath of tuples from it in order to learn. Therefore, we are able to learn from individual tuples multiple times\n",
    "\n",
    "Sequential order runs the risk of getting swayed by the effect of the correlations.\n",
    "\n",
    "With experience replay, can sample from this buffer at random\n",
    "\n",
    "Randomizing the samples breaks these correlations and therefore reduces the variance of the updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "189dba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "# prioritized experience replay\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed, experiences_per_sampling):\n",
    "        '''\n",
    "        Only stroes the last N experience tuples in the replay memory\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "            EXPERIENCES_PER_SAMPLING(int): number of experiences\n",
    "        '''\n",
    "        # Initialize replay memory\n",
    "        self.acion_size = action_size\n",
    "        self.buffer_size = buffer_size\n",
    "        ##### Prioritization\n",
    "#         self.memory = deque(maxlen=buffer_size) # set N memory size\n",
    "        #####\n",
    "        self.batch_size = batch_size\n",
    "        # build named experience tuples\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "        ##### Prioritization\n",
    "        self.experiences_per_sampling = experiences_per_sampling\n",
    "        \n",
    "        self.alpha = 0.5\n",
    "        self.alpha_decay_rate = 0.99\n",
    "        self.beta = 0.5\n",
    "        self.beta_growth_rate = 1.001\n",
    "        self.experience_count = 0\n",
    "        self.data = namedtuple(\"Data\", field_names=[\"priority\", \"probability\", \"weight\",\"index\"])\n",
    "        \n",
    "        indexes = []\n",
    "        datas = []\n",
    "        for i in range(buffer_size):\n",
    "            indexes.append(i)\n",
    "            d = self.data(0,0,0,i)\n",
    "            datas.append(d)\n",
    "        \n",
    "        self.memory = {key: self.experience for key in indexes}\n",
    "        self.memory_data = {key: data for key,data in zip(indexes, datas)}\n",
    "        self.sampled_batches = []\n",
    "        self.current_batch = 0\n",
    "        self.priorities_sum_alpha = 0\n",
    "        self.priorities_max = 1\n",
    "        self.weights_max = 1\n",
    "\n",
    "    def update_priorities(self, tds, indices):\n",
    "        for td, index in zip(tds, indices):\n",
    "            N = min(self.experience_count, self.buffer_size)\n",
    "\n",
    "            updated_priority = td[0]\n",
    "            if updated_priority > self.priorities_max:\n",
    "                self.priorities_max = updated_priority\n",
    "            if self.weights_max > 0:\n",
    "                updated_weight = ((N * updated_priority)**(-self.beta))/self.weights_max\n",
    "                if updated_weight > self.weights_max:\n",
    "                    self.weights_max = updated_weight\n",
    "\n",
    "\n",
    "            old_priority = self.memory_data[index].priority\n",
    "            self.priorities_sum_alpha += updated_priority**self.alpha - old_priority**self.alpha\n",
    "            updated_probability = td[0]**self.alpha / self.priorities_sum_alpha\n",
    "            data = self.data(updated_priority, updated_probability, updated_weight, index) \n",
    "            self.memory_data[index] = data\n",
    "\n",
    "    def update_memory_sampling(self):\n",
    "        \"\"\"Randomly sample X batches of experiences from memory.\"\"\"\n",
    "        # X is the number of steps before updating memory\n",
    "        self.current_batch = 0\n",
    "        values = list(self.memory_data.values())\n",
    "        random_values = random.choices(self.memory_data, \n",
    "                                       [data.probability for data in values], \n",
    "                                       k=self.experiences_per_sampling)\n",
    "        self.sampled_batches = [random_values[i:i + self.batch_size] \n",
    "                                    for i in range(0, len(random_values), self.batch_size)]\n",
    "\n",
    "    def update_parameters(self):\n",
    "        self.alpha *= self.alpha_decay_rate\n",
    "        self.beta *= self.beta_growth_rate\n",
    "        if self.beta > 1:\n",
    "            self.beta = 1\n",
    "        N = min(self.experience_count, self.buffer_size)\n",
    "        self.priorities_sum_alpha = 0\n",
    "        sum_prob_before = 0\n",
    "        for element in self.memory_data.values():\n",
    "            sum_prob_before += element.probability\n",
    "            self.priorities_sum_alpha += element.priority**self.alpha\n",
    "        sum_prob_after = 0\n",
    "        for element in self.memory_data.values():\n",
    "            probability = element.priority**self.alpha / self.priorities_sum_alpha\n",
    "            sum_prob_after += probability\n",
    "            weight = 1\n",
    "            if element.probability > 0.0:\n",
    "                weight = ((N *  element.probability)**(-self.beta))/self.weights_max\n",
    "            d = self.data(element.priority, probability, weight, element.index)\n",
    "            self.memory_data[element.index] = d\n",
    "\n",
    "        #####\n",
    "        \n",
    "#     def add(self, state, action, reward, next_state, done):\n",
    "#         '''\n",
    "#         we store the agent's experiences at each time-step, e_t = (s_t,a_t,r_t,s_(t+1))\n",
    "#         '''\n",
    "#         e = self.experience(state, action, reward, next_state, done)\n",
    "#         self.memory.append(e)\n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        self.experience_count += 1\n",
    "        index = self.experience_count % self.buffer_size\n",
    "\n",
    "        if self.experience_count > self.buffer_size:\n",
    "            temp = self.memory_data[index]\n",
    "            self.priorities_sum_alpha -= temp.priority**self.alpha\n",
    "            if temp.priority == self.priorities_max:\n",
    "                self.memory_data[index].priority = 0\n",
    "                self.priorities_max = max(self.memory_data.items(), key=operator.itemgetter(1)).priority\n",
    "\n",
    "            if temp.weight == self.weights_max:\n",
    "                self.memory_data[index].weight = 0\n",
    "                self.weights_max = max(self.memory_data.items(), key=operator.itemgetter(2)).weight\n",
    "\n",
    "        priority = self.priorities_max\n",
    "        weight = self.weights_max\n",
    "        self.priorities_sum_alpha += priority ** self.alpha\n",
    "        probability = priority ** self.alpha / self.priorities_sum_alpha\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory[index] = e\n",
    "        d = self.data(priority, probability, weight, index)\n",
    "        self.memory_data[index] = d\n",
    "                    \n",
    "    def sample(self):\n",
    "        '''\n",
    "        Samples uniformly at random from D(D_t = {e_1,...,e_t}) when  performing updates\n",
    "        '''\n",
    "        # D\n",
    "#         experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        #####\n",
    "        sampled_batch = self.sampled_batches[self.current_batch]\n",
    "        self.current_batch += 1\n",
    "        experiences = []\n",
    "        weights = []\n",
    "        indices = []\n",
    "        \n",
    "        for data in sampled_batch:\n",
    "            experiences.append(self.memory.get(data.index))\n",
    "            weights.append(data.weight)\n",
    "            indices.append(data.index)\n",
    "        \n",
    "        #####\n",
    "        #store in\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device) # gpu\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "        # return D\n",
    "#         return (states, actions, rewards, next_states, dones)\n",
    "        #####\n",
    "        return (states, actions, rewards, next_states, dones, weights, indices)\n",
    "    \n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Return the current size of internal memory\n",
    "        '''\n",
    "        return len(self.memory)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbcb7fe",
   "metadata": {},
   "source": [
    "### Implement agent\n",
    "* Agent(state_size=8, action_size=4, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd74428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# hyperparameters\n",
    "LR = 5e-4                # learning rate\n",
    "BUFFER_SIZE = int(1e5)   # replay buffer size N\n",
    "BATCH_SIZE = 64          # minibatch size\n",
    "UPDATE_EVERY = 4         # how often to update the network\n",
    "GAMMA = 0.99             # Discount factor\n",
    "TAU = 1e-3               # for soft update of target parameters\n",
    "\n",
    "\n",
    "\n",
    "##### prioritized experience replay\n",
    "UPDATE_MEM_EVERY = 20          # how often to update the priorities\n",
    "UPDATE_MEM_PAR_EVERY = 3000     # how often to update the hyperparameters\n",
    "EXPERIENCES_PER_SAMPLING = math.ceil(BATCH_SIZE * UPDATE_MEM_EVERY / UPDATE_EVERY)\n",
    "#####\n",
    "\n",
    "\n",
    "\n",
    "# Setup Gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Build Agent(): Evaluate our agent on unmodified games (dqn agent)\n",
    "class Agent():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, state_size, action_size, seed): #8, 4, 0\n",
    "        \"\"\"\n",
    "        Initialize an Agent object.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state = 8\n",
    "            action_size (int): dimension of each action = 4\n",
    "            seed (int): random seed = 0\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        \n",
    "        # Q-Network: Neural network function approx. with weights theta θ as a Q-Network.\n",
    "        # A Q-Network can be trained by adjusting the parameters θ_i at iteration i to reduce the mse in the Bellman equation\n",
    "        # The outputs correspond to the predicted Q-values of the individual action for input state\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device) # gpu\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        # specify optimizer(Adam)\n",
    "        # optim.Adam(Qnet.parameters(), small learning rate)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR) ###\n",
    "        \n",
    "        # First, use a technique known as experience replay in which we stre the agent's experience at each time-step,\n",
    "        # e_t= (s_t, a_t, r_t, s_(t_1)), in a data set D_t ={e_1,...,e_t},pooled over many episodes(where the end of an episode occurs when\n",
    "        # a terminal state is reached) into a replay memory.\n",
    "        #Initialize replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed, EXPERIENCES_PER_SAMPLING) ###\n",
    "        # Initialize time step (update every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "        \n",
    "        ##### Prioritization\n",
    "        self.t_step_mem_par = 0\n",
    "        self.t_step_mem = 0\n",
    "        #####\n",
    "        \n",
    "        \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps\n",
    "        self.t_step =(self.t_step + 1) % UPDATE_EVERY\n",
    "        \n",
    "        \n",
    "        ##### Prioritization\n",
    "        self.t_step_mem = (self.t_step_mem + 1) % UPDATE_MEM_EVERY\n",
    "        self.t_step_mem_par = (self.t_step_mem_par + 1) % UPDATE_MEM_EVERY\n",
    "        \n",
    "        if self.t_step_mem_par == 0:\n",
    "            self.memory.update_parameters()\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if self.memory.experience_count > EXPERIENCES_PER_SAMPLING:\n",
    "                sampling = self.memory.sample()\n",
    "                self.learn(sampling, GAMMA)\n",
    "        if self.t_step_mem == 0:\n",
    "            self.memory.update_memory_sampling()\n",
    "\n",
    "        #####\n",
    "        \n",
    "#         if self.t_step == 0:\n",
    "#             # if enough samples are availabe in memory, get random subset and learn\n",
    "#             if len(self.memory) > BATCH_SIZE: ###\n",
    "#                 experiences = self.memory.sample()\n",
    "#                 self.learn(experiences, GAMMA) ###\n",
    "                \n",
    "    def act(self, state, eps=0):\n",
    "        '''\n",
    "        Choose action A from state S using policy pi <- epsilon-Greedt(q^hat (S,A,w))\n",
    "        Return actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection        \n",
    "        '''\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "        \n",
    "        # It is off-policy: it learns about the greedy policy a = argmax Q(s,a';θ),\n",
    "        # while following a behaviour distribution is often selected by an eps-greedy policy\n",
    "        # that follows the greey policy with probability 1-eps and selects a random action\n",
    "        # with probability eps.        \n",
    "        # Epsilon-greedy action selection\n",
    "        # \n",
    "        # with probability epsilon select a random action a_t\n",
    "        # otherwise select a_t = argmax_a Q (phi(s_t),a; θ)\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "        \n",
    "    def learn(self, sampling, gamma): #----only use the local and target Q-networks to compute the loss before taking a step towards minimizing the loss\n",
    "        '''\n",
    "        Update value parameters using given batch of experience tuples\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Variable]): tuple of (s, a, r, s', done) tuples\n",
    "            gamma (float): discount factor\n",
    "        \n",
    "        '''\n",
    "        states, actions, rewards, next_states, dones, weights, indices = sampling\n",
    "        #####DQN\n",
    "        ## Get max predicted Q values (for next states) from target model\n",
    "        #Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        #\n",
    "        ## Compute Q targets for current states\n",
    "        #Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "        #\n",
    "        ## Get expected Q values from local model\n",
    "        #Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "        \n",
    "        ##### Double DQN\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            # fetch max action arguemnt to pass\n",
    "            Q_pred = self.qnetwork_local(next_states)\n",
    "            max_actions = torch.argmax(Q_pred, dim=1).long().unsqueeze(1)\n",
    "            # Q_targets over next statesfrom actions will be taken based on Q_pred's max_action\n",
    "            Q_next = self.qnetwork_target(next_states)\n",
    "        self.qnetwork_local.train()\n",
    "        Q_targets = rewards + (gamma * Q_next.gather(1, max_actions) * (1.0 - dones))\n",
    "        ## Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "        \n",
    "        \n",
    "        ###############\n",
    "        # apply loss fucntion\n",
    "        # calculate the loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        \n",
    "        ##### Prioritization\n",
    "        if len(weights) > 0:\n",
    "            with torch.no_grad():\n",
    "                weight = sum(np.multiply(weights, loss.cpu().data.numpy()))\n",
    "                loss *= weight\n",
    "        #####\n",
    "        \n",
    "        \n",
    "        \n",
    "        # zero the parameter (weight) gradients\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # backward pass to calculate the parameter gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the parameters\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        #################\n",
    "        #Update target network\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU) ###\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##### Prioritization\n",
    "        delta = abs(Q_targets - Q_expected.detach()).cpu().numpy()\n",
    "        self.memory.update_priorities(delta, indices)  \n",
    "        #####\n",
    "        \n",
    "        \n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau * local_param.data + (1.0 - tau) * target_param.data)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97d648e",
   "metadata": {},
   "source": [
    "# Watch an untrained agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e37c8bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "\n",
    "state = env.reset()\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "for j in range(200):\n",
    "    action = agent.act(state)\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    plt.axis('off')\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dbd6b6",
   "metadata": {},
   "source": [
    "# Train the Agent with DQN\n",
    "Train Deep Q-Learning with\n",
    "* maximum number of training episodes: 2000\n",
    "* maximum number of timesteps per episode: 1000\n",
    "* starting value of epsilon for epsilon-greedy action selection: 1.0\n",
    "* minimum value of epsilon: 0.01\n",
    "* multiplacative factor (per episode for decreasing epsilon: 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91021fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\t Average Score:-188.011\n",
      "Episode 200\t Average Score:-100.666\n",
      "Episode 261\t Average Score: -49.64"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-a600e3695345>:62: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  updated_weight = ((N * updated_priority)**(-self.beta))/self.weights_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 300\t Average Score:-39.944\n",
      "Episode 400\t Average Score:69.6556\n",
      "Episode 500\t Average Score:120.822\n",
      "Episode 547\t Average Score: 113.44"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-a600e3695345>:62: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  updated_weight = ((N * updated_priority)**(-self.beta))/self.weights_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600\t Average Score:128.633\n",
      "Episode 700\t Average Score:138.166\n",
      "Episode 800\t Average Score:164.144\n",
      "Episode 900\t Average Score:193.566\n",
      "Episode 916\t Average Score: 200.51\n",
      "Environment solved in 816 episodes!\tAverage Score: 200.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#double dqn\n",
    "def dqn(n_episodes = 2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"\n",
    "    Train the Agent with Deep Q-Learning\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    # Initialize collecting scores from each episode\n",
    "    scores = []\n",
    "    # Initialize collecting maxlen(100) scores\n",
    "    scores_window = deque(maxlen=100)\n",
    "    # initialize starting value of epsilon\n",
    "    eps = eps_start\n",
    "    \n",
    "    # for each episode----------------\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        # begin the episode\n",
    "        state = env.reset()\n",
    "        # initialize the sampled score(reward)\n",
    "        score = 0\n",
    "        \n",
    "        # Set constrain maximum number of time step per episode\n",
    "        for t in range(max_t):\n",
    "            # agent select an action\n",
    "            action = agent.act(state, eps)\n",
    "            # agent performs the selected action\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            # agent performs internal updates based on sampled experience\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            # update the sampled reward\n",
    "            score += reward\n",
    "            # update the state (s <- s') to next time step\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "        #Save most recent score\n",
    "        scores_window.append(score)\n",
    "        #save most recent score\n",
    "        scores.append(score)\n",
    "        #Decrease epsilon\n",
    "        eps = max(eps_end, eps_decay*eps)\n",
    "        \n",
    "        # monitor progress\n",
    "        print('\\rEpisode {}\\t Average Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        # get average reward from last 100 episodes\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\t Average Score:{:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=200.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100,\n",
    "                                                                                         np.mean(scores_window)))\n",
    "            # save model\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "#double dqn\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6b25cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the weights from file\n",
    "agent.qnetwork_local.load_state_dict(torch.load('checkpoint.pth'))\n",
    "\n",
    "for i in range(7):\n",
    "    state = env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "    for j in range(500):\n",
    "        action = agent.act(state)\n",
    "        img.set_data(env.render(mode='rgb_array')) \n",
    "        plt.axis('off')\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            break \n",
    "            \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ceb894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0bd6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b601e43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
